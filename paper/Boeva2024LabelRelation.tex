\documentclass[a4paper, 12pt]{article} %{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}
\renewcommand{\abstractname}{Аннотация}


\title{Выявление взаимозависимости между метками с использованием алгоритма, основанного на собственном внимании в задаче классификации с несколькими метками.}

\author{ Боева Галина\\
	Антиплагиат\\
	Сколтех\\ 
	\texttt{boeva.gl@phystech.edu} 
	\AND
        Консультант: к.ф.-м.н. Грабовой Андрей\\
	Антиплагиат\\
	\texttt{grabovoy.av@phystech.edu} 
        \AND
        Эксперт: к.ф.-м.н. Зайцев Алексей\\
	Сколтех\\
	\texttt{a.zaytsev@skoltech.ru}
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{\today}

%\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
Большая часть доступной пользовательской информации может быть представлена в виде последовательности событий с временными метками. Каждому событию присваивается набор категориальных меток, будущая структура которых представляет большой интерес. Это задача прогнозирования временных наборов для последовательных данных. Современные подходы фокусируются на архитектуре преобразования последовательных данных, используя собственного внимания(``self-attention'') к элементам в последовательности. В этом случае мы учитываем временные взаимодействия событий, но теряем информацию о взаимозависимостях меток. Мотивированные этим недостатком, мы предлагаем использовать механизм собственного внимания(``self-attention'') к меткам, предшествующим прогнозируемому шагу. Поскольку наш подход представляет собой сеть внимания к меткам, мы называем ее LANET. Мы также обосновываем этот метод агрегирования, он положительно влияет на интенсивность события, предполагая, что мы используем стандартный вид интенсивности, предполагая работу с базовым процессом Хоукса.
\end{abstract}


\keywords{временные ряды \and взаимосвязь меток}

\section{Введение}
Классификация с несколькими метками является более естественной, чем бинарная или многоклассовая классификация, поскольку все, что окружает нас в реальном мире, обычно описывается несколькими метками~\cite{liu2021emerging}. Та же логика может быть перенесена на последовательность событий с отметками времени. События в последовательности, как правило, характеризуются несколькими категориальными значениями вместо одной. Существует множество подходов к классификации с несколькими метками в компьютерном зрении ~\cite{durand2019learning}, обработке естественного языка ~\cite{xiao2019label} или классической структуре табличных данных ~\cite{tarekegn2021review}. Однако постановке задачи с несколькими метками для последовательностей событий, как правило, уделяется меньше внимания. Итак, мы стремимся противостоять такому недостатку внимания и решить проблему предсказания набора меток для последовательных данных с временными метками.  
\begin{figure*}
    \centering
    \includegraphics[scale=0.75]{images/nir_inrto.pdf}
    \caption{На рисунке показано визуальное представление постановки задачи. Наша модель должна предсказать метки для момента времени $t_4$, учитывая историю предыдущих наборов меток. Требуется предсказать несколько меток, так что это определение задачи классификации с несколькими метками.}
    \label{fig:nir-intro}
\end{figure*}
Важно отметить, что модель должна предсказывать набор меток, соответствующих следующему шагу, принимая во внимание содержимое предыдущих групп меток для последовательности событий, связанных с объектом(Рисунок~\ref{fig:nir-intro}).

Взаимодействие между состояниями объекта в разные временные метки имеет важное значение для решения задач с последовательными данными~\cite{hartvigsen2020recurrent}. Следовательно, выразительные и мощные модели должны быть способны изучать такие взаимодействия. Несколько архитектур нейронных сетей, таких как трансформеры или рекуррентные нейронные сети, способны делать это. Например, трансформер напрямую определяет механизм внимания, который измеряет, как связаны различные временные метки в последовательности. Однако применение современных методов глубокого обучения ограничено~\cite{zhang2020multi}, и они в первую очередь сосредоточены на прогнозировании меток для последовательности в целом. 

\paragraph{\textbf{Основные подходы для задачи классификации с несколькими метками.}}
Постановка задачи классификации с несколькими метками возникает во многих различных областях, например, при категоризации текста или тегировании изображений, и все они влекут за собой свои собственные особенности и проблемы. В обзоре~\cite{zhang2013review} исследуются основы обучения с использованием нескольких меток, обсуждаются хорошо зарекомендовавшие себя методы, а также самые последние подходы. Возникающие тенденции рассматриваются в более свежем обзоре ~\cite{liu2021emerging}.

В работе~\cite{shou2023concurrent} рассматривается та же постановка задачи классификации с несколькими метками в потоке событий, что и у нас. Модель авторов нацелена на фиксацию временных и вероятностных зависимостей между типами параллельных событий путем кодирования исторической информации с помощью энкодера, а затем использования условной смеси экспертов Бернулли. В этой статье~\cite{yu2023continuous} обсуждается постановка задачи прогнозирования временных наборов для пользователей, она предлагает систему непрерывного обучения, которая позволяет явно фиксировать изменяющиеся пользовательские предпочтения, поддерживая банк памяти, который мог бы хранить состояния всех пользователей и элементов. В этой парадигме авторы строят неубывающую универсальную последовательность, содержащую все пользовательские взаимодействия, а затем в хронологическом порядке извлекают уроки из каждого взаимодействия. Для исследования взаимосвязи между продуктами в корзине был предложен ConvTSP~\cite{zhang2023conv}, который объединяет динамические интересы пользователей и статистические интересы в единое векторное представление.

\paragraph{\textbf{Рекомендательные системы.}}
В этом разделе мы представим статьи, связанные с проблемой рекомендации следующей корзины. Эта формулировка похожа на нашу, поэтому мы также рассмотрели многие подходы и идеи при анализе нашей области исследований. Авторы в ~\cite{ariannezhad2023personalized} предложили персонализированную модель, которая фиксирует краткосрочные зависимости внутри временного набора продуктов, а также долгосрочную, основанную на исторической информации о пользователях. Также в ~\cite{yannam2023hybrid} для соединения локальной и глобальной пользовательской информации предлагается гибридный метод, основанный на автоэнкодере для извлечения контекста и RNN для понимания динамики изменения интересов. Чтобы преодолеть подобные проблемы, для предсказания следующей рекомендации создается сеть внимания на основе графов, использующая hyper-edge подход~\cite{song2023hgat}.
При такой постановке задачи возникает сложность работы со словарем товарных категорий, поскольку они насчитывают тысячи значений, ~\cite{van2023next} использует GRU для прогнозирования следующей корзины, которая легко масштабируется до большого ассортимента.


\paragraph{\textbf{Вклад.}}
Мы разработали архитектуру на основе трансформера на основе собственного внимания между метками для работы над задачей классификации последовательностей событий по нескольким меткам. Наш основной вклад заключается в следующем:
\begin{itemize}
    \item Мы вводим архитектуру LANET для прогнозирования набора меток для текущего события, используя информацию из предыдущих событий. Особенностью архитектуры является вычисление собственного внимания между представлениями меток.  
    \item LANET превосходит модели на основе трансформера, которые фокусируются на вычислении собственного внимания между временными метками. Мы оцениваем все показатели в различных наборах данных(будет дополнение).
\end{itemize}


\section{Постановка задачи}
Мы рассмотрим классификацию с несколькими метками для последовательности $S = \{(X_{i}, Y_{i})\}_{i = 1}^{t-1}$. Он состоит из набора меток $Y_i$ и набора признаков $X_{i}$, специфичных для каждой временной метки от $1$ до $t-1$. Индекс соответствует времени события, поэтому $(X_{1}, Y_{1})$ - это информация о первом событии, а $(X_{t-1}, Y_{t-1})$ - это информация о последнем наблюдаемом событии.
Множество $Y_i \subseteq \mathcal{Y}$, где $\mathcal{Y} = \{1, 2, \dots, K\}$ - это множество всех возможных меток. Установленный размер $X_{i}$ равен размеру $Y_{i}$. Каждая метка из $Y_{i}$ сопровождается числовым или категориальным признаком из $X_{i}$ в соответствующей позиции.

У нас также может быть дополнительный вектор признаков $\mathbf{z}$, описывающий рассматриваемую последовательность $S$ в целом, например, идентификатор пользователя.
Цель последовательной классификации с несколькими метками состоит в том, чтобы предсказать набор меток $Y_{t}$ для следующей временной метки.

Мы создаем функцию $f(\cdot) \in [0, 1]^K$, которая принимает историческую информацию о событиях в качестве входных данных и выводит вектор оценок для каждой из меток $K$. Эти оценки представляют собой вероятности присутствия метки в следующем наборе, связанных с событием.

В нашей настройке мы ограничиваем размер прошлого, доступного модели.
$S^t = \{(X_{j}, Y_{j})\}_{j = t - \tau}^{t-1}$, где $\tau$ означает количество событий, предшествующих рассматриваемому событию, с отметкой времени $t$, которая равна приписывается целевому набору меток $Y_{t}$.
Итак, более формально $f(\cdot)$ имеет вид:
$$
f(X_{t - \tau}, \ldots, X_{t-1}, Y_{t - \tau}, \ldots, Y_{t-1}, \textbf{z}) \in [0, 1]^K
$$
для предсказания $Y_{t}$.

Чтобы завершить прогноз, нам нужна отдельная модель принятия решений о метках $g(f(\cdot))$, которая преобразует доверительные баллы в метки.
Например, мы сравниваем оценку для $k$-й метки с выбранным пороговым значением $\beta_k$: если $f_k(\cdot) > \beta_k, k = 1, \dots, K$, то модель предсказывает, что $k$-я метка присутствует. Таким образом, модель $g$ создает набор меток $\hat{Y}_{t} \subseteq \mathcal{Y}$ на основе входных оценок достоверности.

Результирующее качество модели зависит как от метода $g(\cdot)$ для выбора меток для конечного набора, так и от производительности $f(\cdot)$ для получения достоверных оценок, в то время как мы сосредоточены на работе с $f(\cdot)$. Далее мы преобразуем задачу классификации с несколькими метками в задачи множественной бинарной классификации и оптимизируем модель, минимизируя потери перекрестной энтропии.

 
\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
